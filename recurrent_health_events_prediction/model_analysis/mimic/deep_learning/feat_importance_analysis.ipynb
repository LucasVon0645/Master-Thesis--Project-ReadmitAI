{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd4ab7d",
   "metadata": {},
   "source": [
    "# Feature Importance with Captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4558ac5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace directory: /workspaces/msc-thesis-recurrent-health-modeling/\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from importlib import import_module\n",
    "\n",
    "WORKSPACE_DIR = '/workspaces/msc-thesis-recurrent-health-modeling/'\n",
    "print(f\"Workspace directory: {WORKSPACE_DIR}\")\n",
    "\n",
    "# ---- User inputs (EDIT ME) ----\n",
    "DATASET_TEST_PT_PATH = f\"{WORKSPACE_DIR}_models/mimic/deep_learning/attention_pooling_query_curr/multiple_hosp_patients/test_dataset.pt\"  # path to test .pt file\n",
    "DATASET_TRAIN_PT_PATH = f\"{WORKSPACE_DIR}_models/mimic/deep_learning/attention_pooling_query_curr/multiple_hosp_patients/train_full_dataset.pt\"  # path to train .pt file\n",
    "MODEL_MODULE = \"recurrent_health_events_prediction.model.RecurrentHealthEventsDL\"\n",
    "MODEL_CLASS_NAME = \"AttentionPoolingNetCurrentQuery\"   # e.g., GRUNet, AttentionPoolingNet, CrossAttnPoolingNet\n",
    "CONFIG_PATH = f\"{WORKSPACE_DIR}_runs/attention_pooling_query_curr_20251020_180454/model_config.yaml\" # path to model config yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e70df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_STATS_PATH = f\"{WORKSPACE_DIR}_models/mimic/deep_learning/training_stats.json\"  # path to training stats json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cfb087c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b683ab2a",
   "metadata": {},
   "source": [
    "## Load datasets and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08804db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config: /workspaces/msc-thesis-recurrent-health-modeling/_runs/attention_pooling_query_curr_20251020_180454/model_config.yaml\n",
      "Model class: AttentionPoolingNetCurrentQuery\n",
      "Model params: {'dropout': 0.014417996600305944, 'hidden_size_head': 64, 'hidden_size_seq': 16, 'input_size_curr': 19, 'input_size_seq': 8, 'scale_scores': False, 'use_separate_values': True}\n"
     ]
    }
   ],
   "source": [
    "if CONFIG_PATH is not None:\n",
    "    import yaml\n",
    "    with open(CONFIG_PATH, \"r\") as f:\n",
    "        model_cfg = yaml.safe_load(f)\n",
    "    MODEL_CLASS_NAME = model_cfg.get(\"model_class\", MODEL_CLASS_NAME)\n",
    "    MODEL_PARAMS = model_cfg.get(\"model_params\")\n",
    "    print(\"Loaded config:\", CONFIG_PATH)\n",
    "else:\n",
    "    print(\"Using inline MODEL_PARAMS.\")\n",
    "print(\"Model class:\", MODEL_CLASS_NAME)\n",
    "print(\"Model params:\", MODEL_PARAMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b2f546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'current_feat_cols': ['LOG_HOSPITALIZATION_DAYS',\n",
       "  'LOG_DAYS_IN_ICU',\n",
       "  'CHARLSON_INDEX',\n",
       "  'LOG_NUM_DRUGS',\n",
       "  'NUM_PROCEDURES',\n",
       "  'LOG_PARTICIPATION_DAYS',\n",
       "  'HAS_DIABETES',\n",
       "  'HAS_COPD',\n",
       "  'HAS_CONGESTIVE_HF',\n",
       "  'DISCHARGE_LOCATION_POST_ACUTE_CARE',\n",
       "  'DISCHARGE_LOCATION_HOME',\n",
       "  'AGE',\n",
       "  'GENDER_M',\n",
       "  'ADMISSION_TYPE_ELECTIVE',\n",
       "  'ETHNICITY_WHITE',\n",
       "  'ETHNICITY_BLACK',\n",
       "  'ETHNICITY_HISPANIC',\n",
       "  'INSURANCE_MEDICAID',\n",
       "  'INSURANCE_PRIVATE'],\n",
       " 'learning_rate': 0.007004792359623531,\n",
       " 'longitudinal_feat_cols': ['LOG_HOSPITALIZATION_DAYS',\n",
       "  'LOG_DAYS_IN_ICU',\n",
       "  'CHARLSON_INDEX',\n",
       "  'LOG_NUM_DRUGS',\n",
       "  'NUM_PROCEDURES',\n",
       "  'DISCHARGE_LOCATION_POST_ACUTE_CARE',\n",
       "  'ADMISSION_TYPE_ELECTIVE',\n",
       "  'LOG_DAYS_UNTIL_NEXT_HOSPITALIZATION'],\n",
       " 'lr_scheduler': 'plateau',\n",
       " 'max_sequence_length': 4,\n",
       " 'model_class': 'AttentionPoolingNetCurrentQuery',\n",
       " 'model_name': 'Attention Pooling with Current-Visit Query',\n",
       " 'model_params': {'dropout': 0.014417996600305944,\n",
       "  'hidden_size_head': 64,\n",
       "  'hidden_size_seq': 16,\n",
       "  'input_size_curr': 19,\n",
       "  'input_size_seq': 8,\n",
       "  'scale_scores': False,\n",
       "  'use_separate_values': True},\n",
       " 'no_elective': True,\n",
       " 'num_epochs': 100,\n",
       " 'reverse_chronological_order': True,\n",
       " 'weight_decay': 0.02683499184486217}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f95073a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current-visit features: \n",
      " - LOG_HOSPITALIZATION_DAYS\n",
      " - LOG_DAYS_IN_ICU\n",
      " - CHARLSON_INDEX\n",
      " - LOG_NUM_DRUGS\n",
      " - NUM_PROCEDURES\n",
      " - LOG_PARTICIPATION_DAYS\n",
      " - HAS_DIABETES\n",
      " - HAS_COPD\n",
      " - HAS_CONGESTIVE_HF\n",
      " - DISCHARGE_LOCATION_POST_ACUTE_CARE\n",
      " - DISCHARGE_LOCATION_HOME\n",
      " - AGE\n",
      " - GENDER_M\n",
      " - ADMISSION_TYPE_ELECTIVE\n",
      " - ETHNICITY_WHITE\n",
      " - ETHNICITY_BLACK\n",
      " - ETHNICITY_HISPANIC\n",
      " - INSURANCE_MEDICAID\n",
      " - INSURANCE_PRIVATE\n"
     ]
    }
   ],
   "source": [
    "current_feat_cols = model_cfg.get(\"current_feat_cols\")\n",
    "print(\"Current-visit features: \")\n",
    "for col in current_feat_cols:\n",
    "    print(\" -\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bee25d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudinal features: \n",
      " - LOG_HOSPITALIZATION_DAYS\n",
      " - LOG_DAYS_IN_ICU\n",
      " - CHARLSON_INDEX\n",
      " - LOG_NUM_DRUGS\n",
      " - NUM_PROCEDURES\n",
      " - DISCHARGE_LOCATION_POST_ACUTE_CARE\n",
      " - ADMISSION_TYPE_ELECTIVE\n",
      " - LOG_DAYS_UNTIL_NEXT_HOSPITALIZATION\n"
     ]
    }
   ],
   "source": [
    "longitudinal_feat_cols = model_cfg.get(\"longitudinal_feat_cols\")\n",
    "print(\"Longitudinal features: \")\n",
    "for col in longitudinal_feat_cols:\n",
    "    print(\" -\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fa2f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset_object type: <class 'recurrent_health_events_prediction.datasets.HospReadmDataset.HospReadmDataset'>\n"
     ]
    }
   ],
   "source": [
    "test_dataset_obj = torch.load(DATASET_TEST_PT_PATH, weights_only=False)\n",
    "train_dataset_obj = torch.load(DATASET_TRAIN_PT_PATH, weights_only=False)\n",
    "print(f\"Loaded dataset_object type: {type(test_dataset_obj)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40973803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of tensors from dataset:\n",
      "x_curr: torch.Size([19])\n",
      "x_past: torch.Size([4, 8])\n",
      "mask: torch.Size([4])\n",
      "label: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "x_curr_ex, x_past_ex, mask_ex, label_ex = train_dataset_obj[0]\n",
    "print(\"Shapes of tensors from dataset:\")\n",
    "print(f\"x_curr: {x_curr_ex.shape}\")\n",
    "print(f\"x_past: {x_past_ex.shape}\")\n",
    "print(f\"mask: {mask_ex.shape}\")\n",
    "print(f\"label: {label_ex.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "406b3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_obj, batch_size=model_cfg[\"batch_size\"], shuffle=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset_obj, batch_size=model_cfg[\"batch_size\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c8a77d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of tensors from DataLoader:\n",
      "x_curr: torch.Size([64, 19])\n",
      "x_past: torch.Size([64, 4, 8])\n",
      "mask: torch.Size([64, 4])\n",
      "label: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "x_curr, x_past, mask, label = next(iter(train_loader))\n",
    "print(\"Shapes of tensors from DataLoader:\")\n",
    "print(\"x_curr:\", x_curr.shape)\n",
    "print(\"x_past:\", x_past.shape)\n",
    "print(\"mask:\", mask.shape)\n",
    "print(\"label:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f7f296e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0650,  0.9799,  0.0150,  ...,  0.0000,  0.0000,  1.4230],\n",
       "         [ 1.2172,  0.3097, -0.3854,  ...,  0.0000,  0.0000,  0.9125],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.2898, -0.8091, -0.3854,  ...,  0.0000,  0.0000,  1.6034],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.2654,  1.3369,  0.0150,  ...,  1.0000,  0.0000,  1.0594],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49667965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionPoolingNetCurrentQuery initialized.\n"
     ]
    }
   ],
   "source": [
    "# Import model class and instantiate\n",
    "mod = import_module(MODEL_MODULE)\n",
    "ModelClass = getattr(mod, MODEL_CLASS_NAME)\n",
    "model = ModelClass(**MODEL_PARAMS).eval()  # eval mode for graph drawing\n",
    "print(model.__class__.__name__, \"initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6323260c",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26bd753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to build a batch (x_current, x_past, mask_past, labels) in a few common cases\n",
    "def extract_batch(dataset_obj, batch_size):\n",
    "    \"\"\"Return a tuple (x_current, x_past, mask_past, labels).\n",
    "    Supports a Dataset, a tuple of tensors, or a dict.\n",
    "    \"\"\"\n",
    "    if hasattr(dataset_obj, '__getitem__') and hasattr(dataset_obj, '__len__'):\n",
    "        # Looks like a Dataset\n",
    "        sample = dataset_obj[0]\n",
    "        if isinstance(sample, (list, tuple)) and len(sample) >= 4:\n",
    "            loader = torch.utils.data.DataLoader(dataset_obj, batch_size=batch_size, shuffle=False)\n",
    "            batch = next(iter(loader))\n",
    "            return batch  # expect (x_current, x_past, mask_past, labels)\n",
    "        else:\n",
    "            raise ValueError(\"Dataset sample does not look like (x_current, x_past, mask_past, labels)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42cb81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_train_stats(train_loader, max_rows_for_median: int = 200_000):\n",
    "    \"\"\"\n",
    "    Compute mean and median of features in training data.\n",
    "    It considers only valid (non-masked) entries for the past features.\n",
    "    Returns:\n",
    "      {\n",
    "        \"mean_curr\":   [D_curr],\n",
    "        \"mean_past\":   [D_long],\n",
    "        \"median_curr\": [D_curr]  (if collected),\n",
    "        \"median_past\": [D_long]  (if collected),\n",
    "        \"has_median\":  bool\n",
    "      }\n",
    "    \"\"\"\n",
    "    sum_curr = None\n",
    "    sum_past = None\n",
    "    n_curr = 0\n",
    "    n_past = 0\n",
    "\n",
    "    # buffers for median (on CPU)\n",
    "    buf_curr = []\n",
    "    buf_past = []\n",
    "    total_rows_curr = 0\n",
    "    total_rows_past = 0\n",
    "    collect_median = True  # we will try; if it exceeds the limit, we fall back\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Support for datasets that return (x_curr, x_past, mask, y) or (x_curr, x_past, mask)\n",
    "        if len(batch) == 4:\n",
    "            x_curr, x_past, mask, _ = batch\n",
    "        else:\n",
    "            x_curr, x_past, mask = batch\n",
    "\n",
    "        x_curr = x_curr.to(\"cpu\", non_blocking=True)\n",
    "        x_past = x_past.to(\"cpu\", non_blocking=True)\n",
    "        mask = mask.to(\"cpu\", non_blocking=True).bool()\n",
    "\n",
    "        B, T, D_long = x_past.shape\n",
    "        D_curr = x_curr.shape[-1]\n",
    "\n",
    "        # --- means ---\n",
    "        # current\n",
    "        sum_curr = (sum_curr if sum_curr is not None else torch.zeros(D_curr)) + x_curr.sum(dim=0)\n",
    "        n_curr += x_curr.size(0)\n",
    "\n",
    "        # past: use only valid rows\n",
    "        valid_rows = x_past[mask]        # [N_valid, D_long]\n",
    "        if valid_rows.numel() > 0:\n",
    "            sum_past = (sum_past if sum_past is not None else torch.zeros(D_long)) + valid_rows.sum(dim=0)\n",
    "            n_past += valid_rows.shape[0]\n",
    "\n",
    "        # --- medianas (opcional, até limite de linhas) ---\n",
    "        if collect_median:\n",
    "            # current\n",
    "            if total_rows_curr + x_curr.size(0) <= max_rows_for_median:\n",
    "                buf_curr.append(x_curr)\n",
    "                total_rows_curr += x_curr.size(0)\n",
    "            else:\n",
    "                collect_median = False\n",
    "            # past\n",
    "            if valid_rows.numel() > 0:\n",
    "                if total_rows_past + valid_rows.shape[0] <= max_rows_for_median:\n",
    "                    buf_past.append(valid_rows)\n",
    "                    total_rows_past += valid_rows.shape[0]\n",
    "                else:\n",
    "                    collect_median = False\n",
    "\n",
    "    mean_curr = sum_curr / max(n_curr, 1)\n",
    "    mean_past = sum_past / max(n_past, 1)\n",
    "\n",
    "    stats = {\n",
    "        \"mean_curr\": mean_curr,\n",
    "        \"mean_past\": mean_past,\n",
    "        \"has_median\": False,\n",
    "    }\n",
    "\n",
    "    if collect_median and len(buf_curr) > 0 and len(buf_past) > 0:\n",
    "        curr_mat = torch.cat(buf_curr, dim=0)          # [N_curr, D_curr]\n",
    "        past_mat = torch.cat(buf_past, dim=0)          # [N_past, D_long]\n",
    "        median_curr = torch.quantile(curr_mat, 0.5, dim=0)   # [D_curr]\n",
    "        median_past = torch.quantile(past_mat, 0.5, dim=0)   # [D_long]\n",
    "        stats.update({\n",
    "            \"median_curr\": median_curr,\n",
    "            \"median_past\": median_past,\n",
    "            \"has_median\": True\n",
    "        })\n",
    "\n",
    "    return stats\n",
    "\n",
    "def make_baselines(x_curr, x_past, mask, strategy=\"zeros\", stats=None):\n",
    "    \"\"\"\n",
    "    Create baseline tensors for current and past features according to strategy.\n",
    "    Args:\n",
    "      x_curr: [B, D_curr] tensor of current features\n",
    "      x_past: [B, T, D_long] tensor of past features\n",
    "      mask:   [B, T] boolean tensor indicating valid past steps\n",
    "      strategy: \"zeros\", \"means\", or \"medians\"\n",
    "      stats: precomputed statistics dict from compute_train_stats (required for \"means\" or \"medians\")\n",
    "    Returns:\n",
    "      base_curr: [B, D_curr] baseline tensor for current features\n",
    "      base_past: [B, T, D_long] baseline tensor for past features\n",
    "    \"\"\"\n",
    "    if strategy == \"zeros\":\n",
    "        base_curr = torch.zeros_like(x_curr)\n",
    "        base_past = torch.zeros_like(x_past)\n",
    "\n",
    "    elif strategy == \"means\":\n",
    "        assert stats is not None and \"mean_curr\" in stats and \"mean_past\" in stats, \\\n",
    "            \"Passe stats com mean_curr/mean_past para strategy='means'.\"\n",
    "        base_curr = stats[\"mean_curr\"].to(x_curr).expand_as(x_curr).clone()\n",
    "        base_past = stats[\"mean_past\"].to(x_past).expand_as(x_past).clone()\n",
    "\n",
    "    elif strategy == \"medians\":\n",
    "        assert stats is not None and stats.get(\"has_median\", False), \\\n",
    "            \"Medianas não disponíveis (a coleta pode ter sido desativada por limite).\"\n",
    "        base_curr = stats[\"median_curr\"].to(x_curr).expand_as(x_curr).clone()\n",
    "        base_past = stats[\"median_past\"].to(x_past).expand_as(x_past).clone()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Estratégia de baseline desconhecida: {strategy}\")\n",
    "\n",
    "    # Zerar baseline nos passos preenchidos (padding) segundo a máscara\n",
    "    base_past = base_past.masked_fill(~mask.unsqueeze(-1), 0.0)\n",
    "    return base_curr, base_past\n",
    "\n",
    "def forward_for_attr(model, x_curr, x_past, mask):\n",
    "    out = model(x_current=x_curr, x_past=x_past, mask_past=mask)\n",
    "    if isinstance(out, tuple):\n",
    "        logits, _ = out\n",
    "    else:\n",
    "        logits = out\n",
    "    return logits\n",
    "\n",
    "def save_training_stats(stats: Dict[str, torch.Tensor], out_json_path: str):\n",
    "    import json\n",
    "    serializable_stats = {}\n",
    "    for k, v in stats.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            serializable_stats[k] = v.cpu().tolist()\n",
    "        else:\n",
    "            serializable_stats[k] = v\n",
    "    with open(out_json_path, \"w\") as f:\n",
    "        json.dump(serializable_stats, f, indent=2)\n",
    "    print(f\"Training data stats saved to: {out_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4744a364",
   "metadata": {},
   "source": [
    "## Feature Importance with Captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fef9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "def global_feature_importance(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device,\n",
    "    n_steps: int = 32,\n",
    "    baseline_strategy: str = \"means\",  # \"zeros\" | \"means\" | \"medians\"\n",
    "    internal_batch_size: int = 64\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    # 1) Estatísticas do train, se necessário\n",
    "    stats = None\n",
    "    if baseline_strategy in [\"means\", \"medians\"]:\n",
    "        stats = compute_train_stats(train_loader, max_rows_for_median=200_000)\n",
    "        print(\"mean_curr shape:\", stats[\"mean_curr\"].shape)\n",
    "        print(\"mean_past shape:\", stats[\"mean_past\"].shape)\n",
    "        print(\"has_median:\", stats[\"has_median\"])\n",
    "\n",
    "    # 2) IG: forward wrapper recebe (x_curr, x_past, mask)\n",
    "    ig = IntegratedGradients(lambda x_c, x_p, m: forward_for_attr(model, x_c, x_p, m))\n",
    "\n",
    "    sum_abs_curr = None         # [D_curr]\n",
    "    sum_abs_past_feat = None    # [D_long]\n",
    "    sum_abs_time = None         # [T]\n",
    "    n_samples = 0\n",
    "\n",
    "    for batch in test_loader:\n",
    "        # Suporta datasets que retornam 3 ou 4 itens\n",
    "        if len(batch) == 4:\n",
    "            x_curr, x_past, mask, y = batch\n",
    "        else:\n",
    "            x_curr, x_past, mask = batch\n",
    "        mask = mask.bool()\n",
    "\n",
    "        # Devices & grads (IG precisa de grad nos inputs)\n",
    "        x_curr = x_curr.to(device).requires_grad_(True)\n",
    "        x_past = x_past.to(device).requires_grad_(True)\n",
    "        mask   = mask.to(device)\n",
    "        if mask.dim() == 3 and mask.shape[-1] == 1:\n",
    "            mask = mask.squeeze(-1)  # [B,T]\n",
    "\n",
    "        # 3) Baselines por batch (shape igual ao do batch corrente)\n",
    "        base_curr, base_past = make_baselines(\n",
    "            x_curr, x_past, mask,\n",
    "            strategy=baseline_strategy,\n",
    "            stats=stats\n",
    "        )\n",
    "\n",
    "        # 4) IG por batch (atribui só em x_curr e x_past; mask vai como arg extra)\n",
    "        attr_curr, attr_past = ig.attribute(\n",
    "            inputs=(x_curr, x_past),\n",
    "            baselines=(base_curr, base_past),\n",
    "            additional_forward_args=(mask,),\n",
    "            target=None,                 # binário: único logit\n",
    "            n_steps=n_steps,\n",
    "            internal_batch_size=internal_batch_size\n",
    "        )\n",
    "\n",
    "        # 5) Agregações (|.| e soma no batch)\n",
    "        b_curr = attr_curr.abs().sum(dim=0)            # [D_curr]\n",
    "        b_past_feat = attr_past.abs().sum(dim=(0, 1))  # [D_long]\n",
    "        b_time = attr_past.abs().sum(dim=(0, 2))       # [T]\n",
    "\n",
    "        sum_abs_curr = b_curr if sum_abs_curr is None else sum_abs_curr + b_curr\n",
    "        sum_abs_past_feat = b_past_feat if sum_abs_past_feat is None else sum_abs_past_feat + b_past_feat\n",
    "        sum_abs_time = b_time if sum_abs_time is None else sum_abs_time + b_time\n",
    "\n",
    "        n_samples += x_curr.size(0)\n",
    "\n",
    "    # 6) Médias por amostra\n",
    "    mean_curr = sum_abs_curr / max(n_samples, 1)\n",
    "    mean_past_feat = sum_abs_past_feat / max(n_samples, 1)\n",
    "    mean_time = sum_abs_time / max(n_samples, 1)\n",
    "\n",
    "    return mean_curr, mean_past_feat, mean_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d9fb98",
   "metadata": {},
   "source": [
    "## Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09181581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_curr shape: torch.Size([19])\n",
      "mean_past shape: torch.Size([8])\n",
      "has_median: True\n",
      "Top features (x_curr):\n",
      " 1. LOG_NUM_DRUGS | Importance: 0.0426\n",
      " 2. LOG_HOSPITALIZATION_DAYS | Importance: 0.0306\n",
      " 3. LOG_PARTICIPATION_DAYS | Importance: 0.0204\n",
      " 4. NUM_PROCEDURES | Importance: 0.0176\n",
      " 5. HAS_CONGESTIVE_HF | Importance: 0.0175\n",
      " 6. CHARLSON_INDEX | Importance: 0.0144\n",
      " 7. HAS_DIABETES | Importance: 0.0128\n",
      " 8. AGE | Importance: 0.0100\n",
      " 9. LOG_DAYS_IN_ICU | Importance: 0.0092\n",
      "10. DISCHARGE_LOCATION_HOME | Importance: 0.0073\n",
      "\n",
      "Top features (x_past):\n",
      " 1. NUM_PROCEDURES | Importance: 0.0114\n",
      " 2. DISCHARGE_LOCATION_POST_ACUTE_CARE | Importance: 0.0089\n",
      " 3. CHARLSON_INDEX | Importance: 0.0086\n",
      " 4. LOG_DAYS_UNTIL_NEXT_HOSPITALIZATION | Importance: 0.0078\n",
      " 5. LOG_NUM_DRUGS | Importance: 0.0074\n",
      " 6. LOG_DAYS_IN_ICU | Importance: 0.0067\n",
      " 7. LOG_HOSPITALIZATION_DAYS | Importance: 0.0042\n",
      " 8. ADMISSION_TYPE_ELECTIVE | Importance: 0.0012\n"
     ]
    }
   ],
   "source": [
    "mean_curr, mean_past_feat, mean_time = global_feature_importance(\n",
    "    model, train_loader, test_loader, device\n",
    ")\n",
    "\n",
    "# Top-k features atuais\n",
    "k = 10\n",
    "top_vals, top_idx = torch.topk(mean_curr, k)\n",
    "print(\"Top features (x_curr):\")\n",
    "for i, (v, idx) in enumerate(zip(top_vals, top_idx)):\n",
    "    feature_name = current_feat_cols[idx.item()] if current_feat_cols is not None else f\"Feature {idx.item()}\"\n",
    "    print(f\"{i+1:2d}. {feature_name} | Importance: {v.item():.4f}\")\n",
    "\n",
    "k = len(longitudinal_feat_cols)\n",
    "# Top-k features históricas\n",
    "top_vals_p, top_idx_p = torch.topk(mean_past_feat, k)\n",
    "print(\"\\nTop features (x_past):\")\n",
    "for i, (v, idx) in enumerate(zip(top_vals_p, top_idx_p)):\n",
    "    feature_name = longitudinal_feat_cols[idx.item()] if longitudinal_feat_cols is not None else f\"Feature {idx.item()}\"\n",
    "    print(f\"{i+1:2d}. {feature_name} | Importance: {v.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22c87a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0306, 0.0092, 0.0144, 0.0426, 0.0176, 0.0204, 0.0128, 0.0051, 0.0175,\n",
       "        0.0052, 0.0073, 0.0100, 0.0042, 0.0024, 0.0047, 0.0054, 0.0015, 0.0071,\n",
       "        0.0055], dtype=torch.float64, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "274af309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "size": 6
         },
         "mode": "lines+markers",
         "type": "scatter",
         "x": {
          "bdata": "AQIDBA==",
          "dtype": "i1"
         },
         "y": {
          "bdata": "hkL9xEovoz+8hXQOoySHP4GH/vCJGXM/W0F96Z12ZT8=",
          "dtype": "f8"
         }
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Importance over time"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "Step"
         }
        },
        "yaxis": {
         "title": {
          "text": "Mean absolute importance"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "y = mean_time.detach().cpu().numpy().ravel()\n",
    "x = np.arange(1, len(y) + 1)\n",
    "\n",
    "fig = go.Figure(go.Scatter(x=x, y=y, mode=\"lines+markers\", marker=dict(size=6)))\n",
    "fig.update_layout(\n",
    "    title=\"Importance over time\",\n",
    "    xaxis_title=\"Step\",\n",
    "    yaxis_title=\"Mean absolute importance\",\n",
    "    template=\"plotly_white\",\n",
    "    width=800,\n",
    "    height=400,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cf484",
   "metadata": {},
   "source": [
    "## Global Feature Importance - 4 past hospitalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ce13dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "def filter_full_mask(dataset):\n",
    "    indices_full_mask = []\n",
    "\n",
    "    for idx, sample in enumerate(dataset):\n",
    "        try:\n",
    "            x_curr, x_past, mask, label = sample\n",
    "        except Exception:\n",
    "            # skip samples with unexpected format\n",
    "            continue\n",
    "\n",
    "        # normalize mask shape to [T]\n",
    "        if mask.dim() == 3 and mask.shape[-1] == 1:\n",
    "            mask = mask.squeeze(-1)\n",
    "        mask = mask.bool()\n",
    "\n",
    "        # check if all time steps are valid\n",
    "        if mask.numel() > 0 and mask.all():\n",
    "            indices_full_mask.append(idx)\n",
    "\n",
    "    print(f\"Found {len(indices_full_mask)} samples with all-true mask.\")\n",
    "    if indices_full_mask:\n",
    "        print(\"Sample indices (preview):\", indices_full_mask[:20])\n",
    "\n",
    "    # create and return filtered subset\n",
    "    return Subset(dataset, indices_full_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "239137f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 samples with all-true mask.\n",
      "Sample indices (preview): [7, 8, 36, 48, 49, 63, 78, 91, 126, 157, 161, 162, 171, 172, 173, 202, 203, 204, 205, 206]\n",
      "Found 693 samples with all-true mask.\n",
      "Sample indices (preview): [49, 50, 51, 52, 80, 114, 115, 116, 117, 134, 143, 144, 145, 146, 147, 148, 197, 198, 213, 214]\n"
     ]
    }
   ],
   "source": [
    "full_mask_test_dataset = filter_full_mask(test_dataset_obj)\n",
    "full_mask_train_dataset = filter_full_mask(train_dataset_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4374ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_mask_test_loader = torch.utils.data.DataLoader(\n",
    "    full_mask_test_dataset, batch_size=model_cfg[\"batch_size\"], shuffle=False\n",
    ")\n",
    "full_mask_train_dataset_loader = torch.utils.data.DataLoader(\n",
    "    full_mask_train_dataset, batch_size=model_cfg[\"batch_size\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "885d543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_curr shape: torch.Size([19])\n",
      "mean_past shape: torch.Size([8])\n",
      "has_median: True\n",
      "\n",
      "Global feature importance (full-mask samples only):\n",
      "Top features (x_curr):\n",
      " 1. LOG_HOSPITALIZATION_DAYS | Importance: 0.0258\n",
      " 2. NUM_PROCEDURES | Importance: 0.0220\n",
      " 3. CHARLSON_INDEX | Importance: 0.0192\n",
      " 4. LOG_NUM_DRUGS | Importance: 0.0185\n",
      " 5. HAS_CONGESTIVE_HF | Importance: 0.0164\n",
      " 6. HAS_DIABETES | Importance: 0.0121\n",
      " 7. INSURANCE_MEDICAID | Importance: 0.0100\n",
      " 8. ETHNICITY_BLACK | Importance: 0.0090\n",
      " 9. ETHNICITY_WHITE | Importance: 0.0082\n",
      "10. LOG_DAYS_IN_ICU | Importance: 0.0079\n",
      "\n",
      "Top features (x_past):\n",
      " 1. NUM_PROCEDURES | Importance: 0.0190\n",
      " 2. DISCHARGE_LOCATION_POST_ACUTE_CARE | Importance: 0.0149\n",
      " 3. LOG_DAYS_IN_ICU | Importance: 0.0121\n",
      " 4. CHARLSON_INDEX | Importance: 0.0108\n",
      " 5. LOG_DAYS_UNTIL_NEXT_HOSPITALIZATION | Importance: 0.0094\n",
      " 6. LOG_NUM_DRUGS | Importance: 0.0089\n",
      " 7. LOG_HOSPITALIZATION_DAYS | Importance: 0.0074\n",
      " 8. ADMISSION_TYPE_ELECTIVE | Importance: 0.0007\n"
     ]
    }
   ],
   "source": [
    "mean_curr, mean_past_feat, mean_time = global_feature_importance(\n",
    "    model, full_mask_train_dataset_loader, full_mask_test_loader, device\n",
    ")\n",
    "print(\"\\nGlobal feature importance (full-mask samples only):\")\n",
    "k = 10\n",
    "top_vals, top_idx = torch.topk(mean_curr, k)\n",
    "print(\"Top features (x_curr):\")\n",
    "for i, (v, idx) in enumerate(zip(top_vals, top_idx)):\n",
    "    feature_name = current_feat_cols[idx.item()] if current_feat_cols is not None else f\"Feature {idx.item()}\"\n",
    "    print(f\"{i+1:2d}. {feature_name} | Importance: {v.item():.4f}\")\n",
    "\n",
    "k = len(longitudinal_feat_cols)\n",
    "# Top-k longitudinal features\n",
    "top_vals_p, top_idx_p = torch.topk(mean_past_feat, k)\n",
    "print(\"\\nTop features (x_past):\")\n",
    "for i, (v, idx) in enumerate(zip(top_vals_p, top_idx_p)):\n",
    "    feature_name = longitudinal_feat_cols[idx.item()] if longitudinal_feat_cols is not None else f\"Feature {idx.item()}\"\n",
    "    print(f\"{i+1:2d}. {feature_name} | Importance: {v.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a2601",
   "metadata": {},
   "source": [
    "## Feature Importance per Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c399b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training stats from: /workspaces/msc-thesis-recurrent-health-modeling/_models/mimic/deep_learning/training_stats.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "if os.path.exists(TRAINING_DATA_STATS_PATH):\n",
    "    with open(TRAINING_DATA_STATS_PATH, \"r\") as f:\n",
    "        raw = json.load(f)\n",
    "    stats = {}\n",
    "    for k, v in raw.items():\n",
    "        # convert lists back to tensors when appropriate\n",
    "        if isinstance(v, list):\n",
    "            stats[k] = torch.tensor(v)\n",
    "        else:\n",
    "            stats[k] = v\n",
    "    print(f\"Loaded training stats from: {TRAINING_DATA_STATS_PATH}\")\n",
    "else:\n",
    "    print(f\"No training stats file found at: {TRAINING_DATA_STATS_PATH}. Will compute stats.\")\n",
    "    # If you want means/medians:\n",
    "    stats = compute_train_stats(train_loader, max_rows_for_median=200_000)\n",
    "    save_training_stats(stats, TRAINING_DATA_STATS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a370e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a batch to explain\n",
    "batch_example = extract_batch(test_dataset_obj, batch_size=8)\n",
    "x_curr_b, x_past_b, mask_b = batch_example[:3]  #\n",
    "\n",
    "# (Optional) layer to split history vs current — for your AttentionPoolingNet:\n",
    "fc1_layer = model.classifier_head[0]  # nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43149fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recurrent_health_events_prediction.model.explainers import explain_deep_learning_model_feat\n",
    "\n",
    "df_curr, df_past, df_split  = explain_deep_learning_model_feat(\n",
    "    model,\n",
    "    x_curr_b[2],\n",
    "    x_past_b[2],\n",
    "    mask_b[2],\n",
    "    current_feat_cols,\n",
    "    longitudinal_feat_cols,\n",
    "    layer_for_split=fc1_layer,\n",
    "    baseline_strategy=\"means\",\n",
    "    stats=stats,\n",
    "    n_steps=64,\n",
    "    internal_batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ef2a863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sample_idx",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "importance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "94393cac-1710-4ce7-adff-a519224ac3a3",
       "rows": [
        [
         "5",
         "0",
         "LOG_PARTICIPATION_DAYS",
         "0.057341703207593214"
        ],
        [
         "1",
         "0",
         "LOG_DAYS_IN_ICU",
         "0.046817399575624905"
        ],
        [
         "7",
         "0",
         "HAS_COPD",
         "0.03126849962278319"
        ],
        [
         "8",
         "0",
         "HAS_CONGESTIVE_HF",
         "0.02804525988802616"
        ],
        [
         "11",
         "0",
         "AGE",
         "0.026688362288963947"
        ],
        [
         "16",
         "0",
         "ETHNICITY_HISPANIC",
         "0.02662256341072054"
        ],
        [
         "4",
         "0",
         "NUM_PROCEDURES",
         "0.015564103485060066"
        ],
        [
         "10",
         "0",
         "DISCHARGE_LOCATION_HOME",
         "0.015541946001677062"
        ],
        [
         "0",
         "0",
         "LOG_HOSPITALIZATION_DAYS",
         "0.013274105819319572"
        ],
        [
         "14",
         "0",
         "ETHNICITY_WHITE",
         "0.01239526026139284"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_idx</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>LOG_PARTICIPATION_DAYS</td>\n",
       "      <td>0.057342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LOG_DAYS_IN_ICU</td>\n",
       "      <td>0.046817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>HAS_COPD</td>\n",
       "      <td>0.031268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>HAS_CONGESTIVE_HF</td>\n",
       "      <td>0.028045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>AGE</td>\n",
       "      <td>0.026688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>ETHNICITY_HISPANIC</td>\n",
       "      <td>0.026623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NUM_PROCEDURES</td>\n",
       "      <td>0.015564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>DISCHARGE_LOCATION_HOME</td>\n",
       "      <td>0.015542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LOG_HOSPITALIZATION_DAYS</td>\n",
       "      <td>0.013274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>ETHNICITY_WHITE</td>\n",
       "      <td>0.012395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_idx              feature_name  importance\n",
       "5            0    LOG_PARTICIPATION_DAYS    0.057342\n",
       "1            0           LOG_DAYS_IN_ICU    0.046817\n",
       "7            0                  HAS_COPD    0.031268\n",
       "8            0         HAS_CONGESTIVE_HF    0.028045\n",
       "11           0                       AGE    0.026688\n",
       "16           0        ETHNICITY_HISPANIC    0.026623\n",
       "4            0            NUM_PROCEDURES    0.015564\n",
       "10           0   DISCHARGE_LOCATION_HOME    0.015542\n",
       "0            0  LOG_HOSPITALIZATION_DAYS    0.013274\n",
       "14           0           ETHNICITY_WHITE    0.012395"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_curr.sort_values(by=\"importance\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfb37b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sample_idx",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "importance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5032840c-9e8c-4f1b-a0e4-cf721457d93b",
       "rows": [
        [
         "0",
         "0",
         "LOG_HOSPITALIZATION_DAYS",
         "0.03925850611867864"
        ],
        [
         "1",
         "0",
         "LOG_DAYS_IN_ICU",
         "0.03882846384806673"
        ],
        [
         "3",
         "0",
         "LOG_NUM_DRUGS",
         "0.03435630951280855"
        ],
        [
         "4",
         "0",
         "NUM_PROCEDURES",
         "0.013395022362992531"
        ],
        [
         "7",
         "0",
         "LOG_DAYS_UNTIL_NEXT_HOSPITALIZATION",
         "0.01139965998958974"
        ],
        [
         "5",
         "0",
         "DISCHARGE_LOCATION_POST_ACUTE_CARE",
         "0.0041052548490856655"
        ],
        [
         "6",
         "0",
         "ADMISSION_TYPE_ELECTIVE",
         "0.002165092628769802"
        ],
        [
         "2",
         "0",
         "CHARLSON_INDEX",
         "0.0011118767685348008"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_idx</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LOG_HOSPITALIZATION_DAYS</td>\n",
       "      <td>0.039259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LOG_DAYS_IN_ICU</td>\n",
       "      <td>0.038828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LOG_NUM_DRUGS</td>\n",
       "      <td>0.034356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NUM_PROCEDURES</td>\n",
       "      <td>0.013395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>LOG_DAYS_UNTIL_NEXT_HOSPITALIZATION</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>DISCHARGE_LOCATION_POST_ACUTE_CARE</td>\n",
       "      <td>0.004105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>ADMISSION_TYPE_ELECTIVE</td>\n",
       "      <td>0.002165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>CHARLSON_INDEX</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_idx                         feature_name  importance\n",
       "0           0             LOG_HOSPITALIZATION_DAYS    0.039259\n",
       "1           0                      LOG_DAYS_IN_ICU    0.038828\n",
       "3           0                        LOG_NUM_DRUGS    0.034356\n",
       "4           0                       NUM_PROCEDURES    0.013395\n",
       "7           0  LOG_DAYS_UNTIL_NEXT_HOSPITALIZATION    0.011400\n",
       "5           0   DISCHARGE_LOCATION_POST_ACUTE_CARE    0.004105\n",
       "6           0              ADMISSION_TYPE_ELECTIVE    0.002165\n",
       "2           0                       CHARLSON_INDEX    0.001112"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_past.sort_values(by=\"importance\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c6c4b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_idx': 0.0,\n",
       " 'past_attribution': 0.08032890434862353,\n",
       " 'current_attribution': 0.33738889031117253}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e10f7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recurrent-health-events-prediction-nvorhdTT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
